# Development Plan

## 1. Status Update
**Date:** November 25, 2025
**Action:** Merged `origin/enhance-rewind-feature` into `main`.

The application has been updated with enhanced history tracking and rewind capabilities. Users can now maintain a history of command logs and analyze them contextually.

## 2. Branch Comparison & Merge Summary

| Feature | `main` (Previous) | `main` (Current - post-merge) |
| :--- | :--- | :--- |
| **Log Storage** | Overwrites `last.log` | Timestamped files: `log_{timestamp}_{slug}.log` |
| **History View** | None | `logtrains history` lists past commands |
| **Analysis Scope** | Last command only | `logtrains analyze --last [N]` (multi-log context) |
| **Setup Script** | Basic `script` command | Helper function with dynamic naming |

## 3. Code Analysis & Issues

### A. Portability (Critical)
The setup script generated by `logtrains setup` uses Linux-specific syntax for the `script` command:
```bash
script -q -c "$*" "$logfile"
```
**Issue:** macOS (BSD) `script` syntax is `script -q logfile command`. The current generated function will fail on macOS.
**Fix:** Detect OS in `Setup` command or generate a cross-platform wrapper.

### B. User Experience / Ambiguity
The `--last N` flag currently **concatenates** the last N logs into a single prompt.
- **Confusion Risk:** Users might expect `--last 2` to analyze the *2nd to last* command, not the *last 2 commands combined*.
- **Recommendation:** Clarify help text or introduce `--select` for specific items vs `--context` for windowed analysis.

### C. Architecture (`llm.rs`)
The `Inferencer` struct in `src/llm.rs` violates Single Responsibility Principle.
- **Responsibilities:** Model downloading, file loading, tokenization, and inference loop are tightly coupled.
- **Hardcoding:** Fallback to "TinyLlama" tokenizer is hardcoded.
- **Improvement:** Refactor into `ModelLoader`, `TokenizerWrapper`, and `InferenceEngine`.

### D. Input Limits
`MAX_INPUT_CHARS` is hardcoded to 12,000.
- **Issue:** Large logs are blindly truncated at the start (keeping the tail).
- **Improvement:** Implement smarter windowing (e.g., keep head + tail, or searchable windows).

## 4. Next Steps

1.  **Fix Setup Script Portability**: Modify `Commands::Setup` to output valid `script` commands for both Linux and macOS based on `std::env::consts::OS`.
2.  **Refactor `llm.rs`**: Extract model loading logic into a separate builder or factory pattern.
3.  **Add Unit Tests**: The project currently lacks unit tests for logic like `get_sorted_log_files` or input sanitization.
4.  **Verify `chrono` dependency**: Ensure `chrono` is properly used and compiled.

## 5. Brainstorming: Future Additions

-   **Interactive TUI (`ratatui`)**: A visual history browser to select logs for analysis without typing IDs/indices.
-   **Daemon Mode**: A background watcher that automatically logs specific commands or errors without manual wrapping.
-   **Conversation Persistence**: Allow the LLM to remember the context of the *previous* explanation for follow-up questions.
-   **Syntax Highlighting**: Use `syntect` to pretty-print the code blocks in the LLM's response.
